Timestamp,Score,Session code (entered automatically),Which version of the content did you interact with? ,Please select your age range,Rate your prior knowledge of machine learning,I feel that I understand the core concepts presented in the game/paper. ,I believe the format I experienced helped me learn presented concepts.,What is an Artificial Neural Network?,Which statement is correct about the Input Layer? ,Which statement is correct about Hidden layers?,What does the Output Layer do? ,What does the Learning Rate affect? ,What effect do Training Cycles have? ,What is a State?,What is Observation Space?,What is Action Space,How does an agent learn? ,What is Exploration?,What is Exploitation?,Why is balancing Exploration vs Exploitation important?,Any additional notes/comments (optional)
10/05/2025 20:28:32,,3787edfa3581459db4af21ada00a2436,I played the game,20 - 24,1,2,3,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A predefined path the agent must follow,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By analyzing the structure of its neural network,Trying unfamiliar actions to discover their outcomes,Changing the observation space during training,Too much exploration can cause the agent to forget past knowledge,
12/05/2025 17:53:17,,a33c11da3afc42aa8b140b32e7ff601b,I played the game,20 - 24,1,4,4,A system built from layers of nodes that work together to process information,It generates reward signals for training,They perform the main processing with weights and activation functions,It controls the learning rate,The number of training cycles allowed,"More cycles allow better learning, but too many can lead to overfitting",Not applicable,Not applicable,Not applicable,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,
12/05/2025 18:25:21,,c8d761fa7ddb4920ae54668aec789f8f,I played the game,20 - 24,2,4,4,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A snapshot of the environment from the agent’s perspective,The set of environments the agent can switch between,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,
12/05/2025 19:22:53,,09baa2f240524eddb3bf0c3c93a4037e,I played the game,20 - 24,1,3,5,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A snapshot of the environment from the agent’s perspective,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,The little Robot that could :D
12/05/2025 19:28:49,,c982aa7a948d45e2a01cdc7f9dc7e091,I played the game,20 - 24,1,3,5,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How many inputs the network accepts,"More cycles allow better learning, but too many can lead to overfitting",A predefined path the agent must follow,The environment's reward distribution,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploration can cause the agent to forget past knowledge,
12/05/2025 19:39:11,,9947843c590a40a48d62f0362b2662ca,I played the game,25 - 29,2,4,5,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A snapshot of the environment from the agent’s perspective,The set of environments the agent can switch between,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,Great interactive game!
12/05/2025 21:29:33,,98ec0160fdd5432a853c52990c19cc5a,I played the game,25 - 29,1,4,5,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A snapshot of the environment from the agent’s perspective,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,
12/05/2025 21:37:19,,,I played the game,30+,3,3,3,A physical network of wires that mimics brain signals,It's the layer where the data is first entered into the network,They are responsible for storing predictions,It returns the final prediction of the network,The number of training cycles allowed,They allow the network to process multiple environments,A snapshot of the environment from the agent’s perspective,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By analyzing the structure of its neural network,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,
12/05/2025 21:44:12,,95b5ac93496e402da1dd81b4d8b92a96,I played the game,30+,2,4,4,A system built from layers of nodes that work together to process information,Not applicable,They are responsible for storing predictions,It returns the final prediction of the network,The number of training cycles allowed,"More cycles allow better learning, but too many can lead to overfitting",A predefined path the agent must follow,The set of environments the agent can switch between,The complete list of all environment objects,By interacting with the environment and updating based on rewards,Repeating the best-known action,Testing random strategies,Too much exploitation can block discovery of better strategies,
12/05/2025 22:03:11,,44a779bd5bb04b1d8d5465f73b3cf25c,I played the game,30+,3,4,4,A database used to store observations and actions for an RL agent,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",The result of a completed training episode,The list of rewards the agent receives,A memory of previously chosen actions,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Testing random strategies,Only exploration leads to long-term learning,
13/05/2025 11:19:12,,4da2428316fc409abf29b6a2f01840e8,I played the game,25 - 29,4,5,4,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A snapshot of the environment from the agent’s perspective,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Not applicable,
13/05/2025 19:24:18,,6e0c2b9371fc4ab9b7e4a3d279c896f0,I played the game,30+,1,2,2,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They only exist in unsupervised learning,It returns the final prediction of the network,How often the network resets,They define how many output categories the network has,A predefined path the agent must follow,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,
17/05/2025 10:28:49,,59c20325bc0741dcbbe7cb93fe1e59ff,I played the game,20 - 24,1,5,5,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A snapshot of the environment from the agent’s perspective,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,
18/05/2025 10:36:37,,77872fcd115d416caffd31922bcadc74,I played the game,25 - 29,2,4,4,A system built from layers of nodes that work together to process information,It's the layer where the data is first entered into the network,They perform the main processing with weights and activation functions,It returns the final prediction of the network,How large each update to the network's weights is during training,"More cycles allow better learning, but too many can lead to overfitting",A snapshot of the environment from the agent’s perspective,What the agent can perceive from its surroundings,The set of possible actions the agent can choose from,By interacting with the environment and updating based on rewards,Trying unfamiliar actions to discover their outcomes,Reusing the best-known actions to maximize rewards,Too much exploitation can block discovery of better strategies,