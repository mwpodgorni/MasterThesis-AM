{
  "InputLayer": {
    "title": "Input Layer",
    "visual": "Images/InputLayer",
    "description": [
      "The input layer is the network’s entry point, where raw data enters.",
      "Each node takes in one feature - such as weight, durability, or material type - and hands it off to the next layer."
    ],
    "highlights": [
      "One node per feature",
      "No computation - just data intake",
      "Feeds raw values into the network",
      "Sets the foundation for all later processing"
    ]
  },
  "HiddenLayers": {
    "title": "Hidden Layers",
    "visual": "Images/HiddenLayers",
    "description": [
      "Hidden layers sit between the input and output and perform the network’s “thinking” by extracting patterns from data.",
      "Each node applies weights and an activation function, passing its result on until the final output layer makes a decision."
    ],
    "highlights": [
      "Stacked layers let the network learn increasingly abstract features",
      "More layers can capture complex relationships - but risk overfitting if overused",
      "Each node transforms its inputs via weighted sums and activations",
      "Choosing the right layer count is key to balancing accuracy and generalization"
    ]
  },
  "OutputLayer": {
    "title": "Output Layer",
    "visual": "Images/OutputLayer",
    "description": [
      "The output layer turns the final activations into your network’s predictions.",
      "Each node represents one category, and the highest value indicates the chosen class."
    ],
    "highlights": [
      "Number of nodes = number of classes",
      "Commonly uses softmax to produce probabilities",
      "Pick the node with the highest output as the decision",
      "Outputs can be interpreted as confidence scores"
    ]
  },
  "TrainingCycle": {
    "title": "Training Cycles",
    "visual": "Images/TrainingCycles",
    "description": [
      "A training cycle (or epoch) means running the entire dataset through the network once.",
      "More cycles can help the network learn better - but too many can lead to overfitting."
    ],
    "highlights": [
      "One cycle = one full pass over all training samples",
      "Increasing cycles usually lowers loss but may overfit",
      "Watch evaluation metrics to find the sweet spot",
      "Longer training takes more time and compute"
    ]
  },
  "LearningRate": {
    "title": "Learning Rate",
    "visual": "Images/LearningRate",
    "description": [
      "The learning rate controls how much the model adjusts during training, whether it is a neural network or a reinforcement learning agent.",
      "A higher learning rate can speed up learning but risks overshooting good solutions; a lower rate leads to slower but more stable progress."
    ],
    "highlights": [
      "Too high → learning may become unstable or inconsistent",
      "Too low → learning can become very slow or stuck",
      "Typical starting values range from 0.001 to 0.1",
      "Adjust based on how training performance changes"
    ]
  },
  "RewardAdjuster": {
    "title": "Reward Adjuster",
    "visual": "Images/RewardAdjuster",
    "description": [
      "Use the Reward Adjuster to assign positive or negative values to each tile in the environment.",
      "These rewards guide the agent’s learning: stepping on high‑value tiles is encouraged, while low or negative values deter the agent."
    ],
    "highlights": [
      "Positive rewards reinforce good actions",
      "Negative rewards discourage mistakes",
      "Zero reward gives no feedback",
      "Balancing rewards speeds up learning"
    ]
  }
}
