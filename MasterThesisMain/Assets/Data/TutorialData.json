{
  "introduction": [
    {
      "title": "Welcome to our robot factory!",
      "content": [
        "As a supervisor, you will assemble and train robots to perform various tasks.",
        "But before you start, you must complete a short training to understand how our robots work."
      ]
    },
    {
      "title": "How do robots learn?",
      "content": [
        "Our robots use machine learning, primarily neural networks and reinforcement learning.",
        "To understand how they learn, we will begin by looking at neural networks, one of the core systems powering their decision making."
      ]
    },
    {
      "title": "What is a neural network?",
      "content": [
        "A neural network is made of layers of connected nodes that transform input data, adjust internal parameters, and improve with training.",
        "With enough data it can detect patterns, make decisions, and improve over time."
      ]
    },
    {
      "title": "Your first task",
      "content": [
        "Before you start to create fully functional robots, you need to prove that you know how to create and use neural networks.",
        "Your first task is to set up a basic neural network and explore its architecture to understand how it processes and learns from data."
      ]
    },
    {
      "title": "Instructions",
      "content": ["Start by opening the workshop."],
      "event": "ShowWorkshopButton"
    },
    {
      "title": "",
      "content": [
        "You can use the workshop to configure, validate, and train your neural networks.",
        "If you are unsure about any part of the workshop, click on a label to view a description of its function.",
        "Now, try to click on the INPUT section to see what it does."
      ],
      "event": "ShowWorkshopButton"
    },
    {
      "title": "",
      "content": [
        "Good job! Now you are ready to configure your first network.",
        "Every neural network needs to have some nodes in INPUT, HIDDEN and OUTPUT layers",
        "Try adding nodes in each layer, then press the \"Test\" button to check if the network is valid."
      ]
    }
  ],
  "firstNetworkNotValid": [
    {
      "title": "Task incomplete",
      "content": [
        "The network is still missing layers or nodes.",
        "Make sure you have at least one node in each layer."
      ]
    }
  ],
  "firstNetworkValid": [
    {
      "title": "Task completed!",
      "content": [
        "Well done. You built your first network and learned its parts.",
        "Next, you will build a network for our sorting robot so that it can classify robot parts."
      ]
    },
    {
      "title": "Your second task",
      "content": [
        "Each robot part has three properties: weight, durability, and material type.",
        "Your neural network needs to analyze these properties and correctly determine what kind of robot it belongs to."
      ]
    },
    {
      "title": "Helpful hints",
      "content": [
        "Match input nodes to properties of robot parts and output nodes to prediction of robot types.",
        "Stacking two hidden layers can help the network learn more complex patterns.",
        "Use a small number of nodes in each hidden layer and adjust as needed."
      ]
    },
    {
      "title": "",
      "content": ["Set up the network and try to test it, before we proceed to training."]
    }
  ],
  "secondNetworkNotValid": [
    {
      "title": "Task incomplete",
      "content": [
        "Your network is not valid.",
        "You should use 3 input nodes for and 3 output nodes, one for each property and one for each robot type.",
        "You should also have 2 hidden layers with 4 nodes in each layer"
      ]
    }
  ],
  "secondNetworkValid": [
    {
      "title": "Task completed!",
      "content": [
        "You successfully set up a neural network that can classify robot parts.",
        "Now, you will need to train the network."
      ]
    },
    {
      "title": "How training works?",
      "content": [
        "Press the Train button to start.",
        "Before training behins, you can adjust the number of training cycles and learning rate using input fields on the right.",
        "Adjust training parameters, press Train button and then, switch to the Evaluation panel to review your network's performance."
      ]
    }
  ],
  "secondNetworkTrainedBad": [
    {
      "title": "Task incomplete",
      "content": [
        "Training of your network did not go well, you need to try again.",
        "Try to increase the number of training cycles.",
        "Keeping low learning rate helps the network adjust more carefully and find better solutions."
      ]
    }
  ],
  "secondNetworkTrainedGood": [
    {
      "title": "Task completed!",
      "content": [
        "You have successfully set up a neural network that can classify robot parts.",
        "Now this network can be used as a brain of our sorting robot."
      ]
    },
    {
      "title": "Your third task",
      "content": [
        "We will move to a different section of the factory, where you will learn more practical applications of machine learning.",
        "Open the Evaluation panel and click Next Level button to continue."
      ]
    }
  ],
  "ReinforcementLearning": [
    {
      "title": "Training Robots with Reinforcement Learning",
      "content": [
        "In this section of the factory, you will train robots to navigate controlled space.",
        "The type of machine learning used here is called reinforcement learning."
      ]
    },
    {
      "title": "What is reinforcement learning?",
      "content": [
        "Reinforcement learning (RL in short) teaches an agent how to make the best decisions by exploring its surroundings and learning from the outcomes.",
        "Based on its actions, the robot receives rewards or penalties that shape its learning and behavior over time."
      ]
    },
    {
      "title": "How does it work?",
      "content": [
        "In RL, the learning is done step by step.",
        "Agents observe the current situation, chooses an action, and receive feedback in a form of a reward.",
        "Over time, by taking many actions and learning from the feedback, agents improve their ability to make better decisions."
      ]
    },
    {
      "title": "",
      "content": [
        "A state describes the environment at that moment.",
        "The agent chooses an action based on its current state and receives a reward based on the action it took."
      ]
    },
    {
      "title": "",
      "content": [
        "When the agent picks an action that we consider good, it receives a positive reward.",
        "If the action is bad, it receives a negative reward.",
        "The agent goes through multiple iterations of this process, learning from its experiences and improving its performance over time."
      ]
    },
    {
      "title": "",
      "content": ["Try opening the workshop window to configure your first robot."],
      "event": "RLShowWorkshopButton"
    }
  ],
  "RLWorkshop": [
    {
      "title": "Your new task",
      "content": [
        "In this section, you need to adjust rewards for different tiles in the environment, to inflence the learning and behavior of the robot.",
        "The robot will receive rewards based on the value you set for each tile it steps on.",
        "You can also adjust the learning rate and number of steps the robot can take in each cycle."
      ]
    },
    {
      "title": "",
      "content": [
        "When you're ready to train the agent, press the Play button to begin the training.",
        "You can also speed up the training by pressing one of the different speed options."
      ]
    },
    {
      "title": "Level 1",
      "content": [
        "The robot needs to learn to navigate the environment and reach the tile with a flag.",
        "Your setup will be evaluated based on how quickly and effectively the robot reaches the target."
      ]
    }
  ],
  "RLPuzzleCompleted": [
    {
      "title": "Training completed!",
      "content": ["The training has been completed. Now open the evaluation tab to see the outcome of the training."]
    }
  ],
  "RLPuzzle1Solved": [
    {
      "title": "Task completed!",
      "content": [
        "You have successfully set up the robot to navigate the enviornment and reach the goal.",
        "When you are ready, proceed to the next level from the Evaluation panel."
      ]
    }
  ],
  "RLPuzzle1NotSolved": [
    {
      "title": "Task incomplete",
      "content": [
        "The configuration is not optimized for the robot to learn and navigate the environment efficiently.",
        "Return to the workshop and give it another try.",
        "Try to keep the reward for the goal tile high, and the reward for the other tiles low."
      ]
    }
  ],
  "RLPuzzle2": [
    {
      "title": "Level 2",
      "content": [
        "Your next task is to set up the rewards so that the robot learns to collect a power-up and defuse malfunctioning robots.",
        "This time, additionally to learning rate and number of steps per cycle, you can also adjust the total number of training cycles."
      ]
    },
    {
      "title": "",
      "content": [
        "Since this task is more complex, the robot may need more time and training to learn the objective.",
        "The way you set the training parameters will influence both the robot's learning speed and its final performance.",
        "Experiment with different settings to find the combination that helps the robot learn efficiently."
      ]
    }
  ],
  "RLPuzzle2Solved": [
    {
      "title": "Task completed!",
      "content": [
        "You have successfully set up the tile rewards, enabling the robot to collect a power-up and defuse the malfunctioning robots.",
        "When you are ready, proceed to the next level from the Evaluation panel."
      ]
    }
  ],
  "RLPuzzle2NotSolved": [
    {
      "title": "Task incomplete",
      "content": [
        "The configuration is not optimized for the robot to learn and navigate the environment efficiently.",
        "Return to the workshop and give it another try.",
        "The robot should prioritize collecting the power-up over defusing the malfunctioning robots.",
        "You should also give it more time to learn by increasing the number of training cycles."
      ]
    }
  ],
  "RLPuzzle3": [
    {
      "title": "New Challenge",
      "content": [
        "This time, set up the tile rewards so the robot learns to collect valuable items, avoid malfunctioning robots, and reach the goal.",
        "Your setup will be evaluated based on the robot's ability to complete the objective efficiently and safely."
      ]
    },
    {
      "title": "",
      "content": [
        "In this section, you will learn about balancing exploration and exploitation, and how the exploration rate setting in the workshop controls this behavior."
      ]
    },
    {
      "title": "Exploration vs. Exploitation",
      "content": [
        "Exploration is when the robot tries out different actions to see what happens. It explores the environment and learns about the consequences of its actions.",
        "Exploitation is then when the robot uses what it has already learned to make the best decisions."
      ]
    },
    {
      "title": "",
      "content": [
        "Both elements are important for the robot to learn effectively.",
        "If the robot only explores, it won learn anything useful. If it focuses only on exploitation, it might not discover optimal actions for certain situations."
      ]
    },
    {
      "title": "Exploration Rate",
      "content": [
        "The exploration rate controls how often the robot chooses to explore instead of exploiting what it already knows.",
        "To balance exploration and exploitation, the robot uses a strategy called epsilon-greedy, where it sometimes explores and sometimes picks the best-known action."
      ]
    },
    {
      "title": "",
      "content": [
        "At first, the robot explores a lot to gather experience. Over time, the exploration rate decreases, and the robot focuses more on making optimal decisions.",
        "You can adjust the exploration rate in the workshop. A higher rate encourages more discovery, while a lower rate focuses on using learned strategies."
      ]
    },
    {
      "title": "",
      "content": ["Try to find the best combination of parameters that will allow the robot to learn efficiently."],
      "event": "RLShowWorkshopButton"
    }
  ],
  "RLPuzzle3Solved": [
    {
      "title": "Task completed!",
      "content": [
        "You have successfully set up the rewards, allowing the robot to collect valuable items and reach the goal.",
        "You have completed the full training and finished the game. Congratulations!"
      ]
    }
  ],
  "RLPuzzle3NotSolved": [
    {
      "title": "Task incomplete",
      "content": [
        "The configuration is not optimized for the robot to learn and navigate the environment efficiently.",
        "Return to the workshop and give it another try.",
        "The robot should prioritize collecting coins and reaching the tile with the flag",
        "This time, it should be punished for encounters with malfunctioning robots."
      ]
    }
  ]
}
